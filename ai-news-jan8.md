**Thoughtworks Tech Radar format**, the news will be categorized into the four quadrants: **Adopt**, **Trial**, **Assess**, and **Hold**, based on their maturity, potential, and current adoption trends.

---

### **Tech Radar Format**

#### **1. Adopt**
**Technologies, tools, or practices that are proven, reliable, and widely adopted.**

- **NVIDIA Cosmos**:
  - Open-source video world model trained on 20 million hours of video.
  - Significant impact on robotics, autonomous driving, and manufacturing.

- **Hugging Face Continual Pre-Training**:
  - Successfully improved math performance on Llama 3.2 3B using 160 billion high-quality tokens.
  - Achieved 2-3x improvement on GSM8K and MATH datasets.

- **NVIDIA Project DIGITS**:
  - Personal AI supercomputer with 128GB unified memory.
  - Practical for local Llama applications and smaller AI models.

- **LM Studio 0.3.6**:
  - Introduced function-calling API and support for local models like Qwen2VL.
  - Improved developer workflows with drive-selection features.

---

#### **2. Trial**
**Emerging tools or methods worth exploring in controlled environments.**

- **Dolphin 3.0**:
  - Cognitive Computations model gaining attention for its performance benchmarks.
  - Recommended for experimentation in LLM applications.

- **Promptimal CLI**:
  - Command-line tool for optimizing prompts using genetic algorithms.
  - Supports custom evaluators and experimental prompt enhancements.

- **AMD Strix Halo**:
  - New mini PC with up to 96GB graphics memory.
  - Promising for local AI workloads, though bandwidth limitations may restrict use cases.

- **Speculative Decoding in Llama.cpp**:
  - Offers up to 60% faster LLM inference without accuracy trade-offs.
  - Useful for applications requiring high-speed processing.

---

#### **3. Assess**
**Promising technologies that need further evaluation to determine their value.**

- **RTX 5090**:
  - Mixed reception due to limited VRAM and questionable marketing comparisons.
  - Requires benchmarking for practical AI workloads.

- **NotebookLM**:
  - Useful for education and structured summaries, but struggles with multitasking and daily usage caps.

- **AI21 Token Management**:
  - Needs transparency regarding payment structures and license agreements.
  - Under scrutiny for perceived privacy and compliance issues.

- **Low-Bit Quantization**:
  - Potential for boosting performance in local Llama2 applications.
  - Requires analysis of trade-offs in quality and speed.

---

#### **4. Hold**
**Tools or approaches that should be avoided or used cautiously due to limitations or concerns.**

- **Cursor IDE**:
  - Frequent performance issues, including laggy compositions and unresponsive links.
  - Recommended to avoid until stability improves.

- **DeepSeek V3**:
  - Data pipeline reliability concerns limit its usability in enterprise settings.
  - Requires resolution of indefinite loading issues.

- **OpenAI Schema Failures**:
  - JSON schema outputs cause persistent errors in prompt engineering tasks.
  - Unreliable for structured data tasks without significant revisions.

- **Perplexity Privacy Issues**:
  - Concerns about targeted ads and data-sharing practices.
  - Trust issues with compliance despite SOC 2 certification.

---

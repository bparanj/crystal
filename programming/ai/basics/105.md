Data Exploration - Structured Data

Objective - To learn the basic principles of applying data exploration techniques, such as Dimensionality Projection and Clustering on structured data.

- Asking the right questions to understand the data
- Understanding how data visualization makes data clearer
- Performing Exploratory Data Analysis using PCA
- Clustering the data through K-means & DBSCAN Clustering
- Evaluating the quality of clusters obtained

Let's break down data exploration with structured data, focusing on dimensionality projection, clustering, and the crucial steps within.

**Understanding Your Structured Data**

1.  **Asking the Right Questions**
    * **Business Goal:**  What problem are you solving?  (Identifying customer segments, finding outliers in financial data, etc.)
    * **Data Characteristics:**
        * What do your rows represent (customers, events, transactions)?
        * What do your columns represent (attributes, features, demographics)?  
        * Data Types: Numbers, categories, datetimes...these influence exploration techniques.

2. **Visualize: The Big Picture** 
    * **Distributions:** Histograms for individual features reveal skewness and outliers.
    * **Correlations:** Heatmaps or scatter plot matrices provide a quick visualization of relationships between numerical features. 
    * **Visual Clues:** Look for unexpected gaps, strange clusters, etc., guiding deeper investigation.

**Exploratory Data Analysis with PCA**

* **Why PCA:** PCA (Principal Component Analysis) is invaluable when you have *many* features in your structured dataset. It helps project data into a lower dimension for easier visualization and pattern detection.
* **How it Works (Simplified):**  Finds "directions" (principal components) that best explain variation in your data, making a condensed representation.
* **What it Offers:**
    * Plot data in 2D/3D along those components, seeing if groups naturally emerge.
    * Find features contributing most to variation, potentially aiding feature selection.

**Clustering: Finding Hidden Structure**

Algorithms to group similar data points. When labels are absent, clustering finds structure that may not be immediately obvious.

* **K-Means**
    * Classic choice: Specify the number of clusters upfront.
    * Works well for reasonably separated clusters.
    * Sensitive to outlier data and initial setup.
* **DBSCAN**
    * Density-based: Doesn't need preset number of clusters; good with irregular cluster shapes.
    * Handles noise points well (things that don't clearly belong to any group).

**Evaluating Cluster Quality**

* **Human Judgment:** Visualizing clustered data to check if groups formed make sense. Domain expertise helps.
* **Metrics:** 
    * Silhouette Coefficient: Measures average similarity within a cluster vs. separation from others.
    * Elbow Method (K-Means): Track within-cluster distance for varying numbers of clusters, aiding cluster count selection. 

**Considerations**

* **Data Cleaning and Preprocessing:** This heavily influences downstream analysis. Handle missing data, consider normalizing numerical features.
* **It's Iterative:** Not just one technique in isolation. You'll explore, revise, try different things.
* **No Substitute for Thinking:** Tools reveal patterns, but you drive interpretation and derive insights. 

## Implementation

An outline and a Python code example that demonstrates how to create a simple animation (video) that shows dimensionality reduction followed by clustering on structured data. We will:

1. Load a dataset (Iris) that has structured data with multiple features.
2. Use PCA for dimensionality reduction (from 4D to 2D for visualization).
3. Apply a clustering algorithm (e.g., K-Means) to the reduced data.
4. Animate the process by:
   - Starting with plotting the data in its reduced 2D form.
   - Iteratively showing how the K-Means cluster centers move and how cluster assignments change over iterations.
5. Save the animation as a video file (e.g., MP4).

**Steps:**

- Load and scale the Iris dataset.
- Perform PCA to project the data into 2 dimensions.
- Run K-Means clustering on the projected data for a specified number of iterations.  
  (Weâ€™ll manually run the iterations and capture each step for the animation.)
- Use `matplotlib.animation.FuncAnimation` to show the step-by-step changes in cluster assignments and center positions.
- Save the result as a video file.

**Code Example (run locally):**

```python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

# Load and preprocess the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target
X_scaled = StandardScaler().fit_transform(X)

# Reduce dimensions to 2D using PCA
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)

# Setup K-Means (we'll manually iterate to show changes)
k = 3
kmeans = KMeans(n_clusters=k, init='random', n_init=1, max_iter=1, random_state=42)
kmeans.fit(X_pca)
labels = kmeans.labels_
centers = kmeans.cluster_centers_

# Number of iterations we want to animate
n_iterations = 10

fig, ax = plt.subplots(figsize=(8,6))

sc = ax.scatter(X_pca[:,0], X_pca[:,1], c=labels, cmap='Set1', s=50, alpha=0.7)
centers_sc = ax.scatter(centers[:,0], centers[:,1], c='black', s=100, marker='X', edgecolors='white')
ax.set_title('Dimensionality Projection (PCA) and K-Means Clustering', fontsize=14)
ax.set_xlabel('PC1')
ax.set_ylabel('PC2')

def init():
    sc.set_offsets(X_pca)
    sc.set_array(labels)
    centers_sc.set_offsets(centers)
    return sc, centers_sc

def update(frame):
    global kmeans, centers, labels
    # Run another iteration of K-Means
    kmeans = KMeans(n_clusters=k, init=centers, n_init=1, max_iter=1, random_state=42)
    kmeans.fit(X_pca)
    labels = kmeans.labels_
    centers = kmeans.cluster_centers_

    sc.set_array(labels)
    centers_sc.set_offsets(centers)
    ax.set_title(f'Iteration {frame+1} of {n_iterations} (on PCA-reduced data)', fontsize=14)
    return sc, centers_sc

anim = animation.FuncAnimation(fig, update, frames=n_iterations,
                               init_func=init, blit=False, repeat=False)

# Save animation as MP4 (requires ffmpeg)
anim.save('dimensionality_clustering_animation.mp4', writer='ffmpeg', fps=1)

plt.show()
```

**What This Does:**

- Projects the Iris dataset onto two principal components so we can visualize it in 2D.
- Runs K-Means clustering step-by-step on the 2D projected data.
- At each iteration, it updates cluster assignments and cluster center positions.
- Produces a `.mp4` file that you can open with a standard media player to watch the clustering process unfold.

**Adjustments and Notes:**

- You can experiment with different dimensionality reduction methods (e.g., UMAP or t-SNE) if you have them installed.
- You can vary the number of iterations or the number of clusters.
- The final result lets you visually see how dimensionality reduction aids in visualizing data and how clustering algorithms behave on the projected space.

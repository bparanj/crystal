Idea behind Time Series Forecasting

Here's a breakdown of the idea behind Time Series Forecasting, explained in a way that should resonate with your programming background:

**The Core Idea**

* **Past Predicts Future:** The fundamental assumption is that there are patterns lurking within historical time series data. If we can uncover those patterns, we might be able to project them into the future.
* **Data as Your Detective Story:** Your historical data is the crime scene. You're searching for clues like trends, cyclical patterns, and even irregularities that could help you reconstruct the most likely "future events" in the story.

**How it Works (Simplified)**

1. **Trend Spotting:**  Is the data generally going up (sales increasing), down (equipment efficiency degrading), or staying level? Forecasting models look to pinpoint these tendencies.

2. **Seasonality Search:** Are there repeating patterns? Do sales spike monthly, or does website traffic rise each weekday morning?  Identifying these cycles is crucial for prediction.

3. **Noise vs. Signal:**  Real-world data is messy. Models try to separate random fluctuations ('noise') from meaningful underlying patterns ('signal') that are likely to continue.

4. **"Fitting the Function":** Imagine your time series data plotted on a graph. Forecasting algorithms essentially attempt to find the best line or curve that describes your data's past behavior. This 'function' is then extended into the future as a prediction.

* **Regression on Steroids:** Time series forecasting is like linear regression but with time as the superstar independent variable. Also, much more focus on trends and cyclical patterns.
* **Dealing with Autocorrelation:** Unlike ordinary datasets, values in time series are often correlated with their neighbors. A 'hot' day is likely to be followed by another hot day.  Models must account for this.
* **Different Model Flavors:** From simple moving averages to complex neural networks (like LSTMs), a whole suite of  algorithms exist, each with strengths and weaknesses for different data types.

**Why Time Series Forecasting is Worthwhile**

* **Future Insight:** Get a 'preview' of what might happen next in sales, product demand, resource usage, etc.
* **Making Informed Decisions:** Forecasts guide planning: Do we have to hire more staff? Increase inventory? Run another marketing promotion?
* **Spotting Anomalies:**  When reality deviates drastically from forecasts, it can signal important changes— equipment failure, a viral social media campaign, etc.

* **Specific forecasting algorithms (ARIMA, LSTM, etc.)**
* **Real-world use cases in different industries** 
* **Challenges of time series forecasting (and how to deal with them!)**

----

Write a Python program for forecasting algorithms ARIMA

Python program that demonstrates how to fit an ARIMA model to a time series for forecasting.

1. Use a well-known time series dataset (the monthly number of airline passengers) available in `statsmodels`.
2. Fit an ARIMA model to the training portion of the data.
3. Forecast future values and compare the forecasted values to the actual data (if available).

**Note:**  

- This example uses `statsmodels`' ARIMA implementation.
- ARIMA models assume stationarity, so real-world usage often involves differencing or applying transformations to achieve a stationary series before fitting the model.
- Adjust ARIMA order parameters `(p,d,q)` as needed, or use tools like `pmdarima`'s auto_arima to select parameters automatically.

**Code**

```python
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.datasets import get_rdataset

# 1. Load a time series dataset
# We'll use the "AirPassengers" dataset, a classic monthly airline passenger count dataset.
# It's available in "datasets" package of R. We can use get_rdataset to fetch it.
data = get_rdataset('AirPassengers', package='datasets').data
# The dataset has a monthly passenger count from 1949 to 1960

# Convert to a time series with a proper datetime index
data['time'] = pd.date_range(start='1949-01-01', periods=len(data), freq='MS')  # monthly start freq
data.set_index('time', inplace=True)
ts = data['value'].astype(float)

# 2. Split the data into training and testing sets
# Let's forecast the last 24 months
train = ts.iloc[:-24]
test = ts.iloc[-24:]

# 3. Fit an ARIMA model
# We'll pick an ARIMA(1,1,1) as a starting guess.
model = ARIMA(train, order=(1,1,1))
model_fit = model.fit()

print(model_fit.summary())

# 4. Forecast for the test period
# steps = length of test set
forecast = model_fit.forecast(steps=len(test))

# 5. Plot the results
plt.figure(figsize=(10,6))
plt.plot(train, label='Training Data')
plt.plot(test, label='Actual Values', color='blue')
plt.plot(forecast, label='Forecasted Values', color='red')
plt.title('ARIMA Forecast')
plt.xlabel('Date')
plt.ylabel('Passengers')
plt.legend()
plt.show()

# Optional: Evaluate forecast performance using a simple metric
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(test, forecast)
print(f"Mean Absolute Error: {mae:.2f}")
```

**What This Code Does:**

- Loads a monthly airline passenger dataset.
- Splits the data into training and testing sets.
- Fits an ARIMA(1,1,1) model to the training data (you can experiment with different orders).
- Forecasts future values over the test period.
- Plots the actual test data against the forecast to visualize performance.
- Computes a simple error metric (MAE) to quantify the forecast accuracy.

**Adjustments:**

- Change the ARIMA parameters `(p,d,q)` to find a better fit.
- Use transformations (e.g., `log` transform) if the data is non-stationary.
- Consider using `auto_arima` from `pmdarima` to automate model selection.  
- Implement other evaluation metrics (e.g., MSE, RMSE, MAPE) to judge forecast performance.

----

Create a video for forecasting algorithms ARIMA

Python code that creates a video to demonstrate how ARIMA forecasting works on a time series.

1. **Scenario:**
   - We have a time series (e.g., monthly airline passengers).
   - We reveal the data incrementally over time.
   - At each frame of the animation:
     - We fit an ARIMA model on the portion of the data revealed so far.
     - We produce a short-term forecast (e.g., the next 12 periods).
     - We plot the historical data, plus the model’s forecast and confidence intervals.

2. **What This Demonstrates:**
   - As we move forward in time, more data is available, and the ARIMA model re-fits on this extended history.
   - The animation shows how the forecast line updates with each new data point incorporated.
   - We can see if forecasts become more accurate as we have more data, and how the forecast line and confidence intervals adjust over time.

- In practice, you might tune ARIMA orders `(p,d,q)` or use `auto_arima` to select parameters.
- Requires `ffmpeg` to save the animation as MP4.
- We use the `AirPassengers` dataset as an example.  
- The computation time for repeatedly fitting ARIMA models might be non-trivial. For a smoother demonstration, consider fewer frames or a shorter forecast horizon.

**Code Example (run locally):**
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.datasets import get_rdataset

# Load the "AirPassengers" dataset
data = get_rdataset('AirPassengers', package='datasets').data
data['date'] = pd.date_range(start='1949-01-01', periods=len(data), freq='MS')
data.set_index('date', inplace=True)
ts = data['value'].astype(float)

# Let's suppose we reveal data month by month and forecast the next 12 months each time
n_forecast = 12
total_points = len(ts)
start_train = 24  # start after we have at least 24 data points

fig, ax = plt.subplots(figsize=(10,6))
ax.set_title("ARIMA Forecast Animation")
ax.set_xlabel("Time")
ax.set_ylabel("Passengers")

line_hist, = ax.plot([], [], 'b-', label='Historical Data')
line_fore, = ax.plot([], [], 'r-', label='Forecast')
line_ci = ax.fill_between([], [], [], color='r', alpha=0.3, label='95% CI')

ax.legend()

def init():
    ax.set_xlim(ts.index[0], ts.index[-1])
    # Set a generous y-limit based on data
    y_min, y_max = ts.min(), ts.max()
    ax.set_ylim(y_min - 50, y_max + 200)
    return line_hist, line_fore, line_ci

def update(frame):
    # frame goes from start_train to total_points-1
    current_end = frame
    train_data = ts.iloc[:current_end]

    # Fit ARIMA model (using a simple ARIMA(1,1,1) as an example)
    # In practice, consider using auto_arima or different orders.
    model = ARIMA(train_data, order=(1,1,1))
    model_fit = model.fit()

    # Forecast next n_forecast steps (if possible)
    if current_end + n_forecast <= total_points:
        forecast_steps = n_forecast
    else:
        # If we're too close to the end, forecast fewer steps
        forecast_steps = total_points - current_end

    forecast = model_fit.get_forecast(steps=forecast_steps)
    fc_mean = forecast.predicted_mean
    fc_conf = forecast.conf_int()

    # Update historical line
    line_hist.set_data(ts.index[:current_end], ts.values[:current_end])

    # Update forecast line if we have forecasts
    if forecast_steps > 0:
        line_fore.set_data(fc_mean.index, fc_mean.values)
        ax.collections.clear()  # remove old confidence intervals
        ax.fill_between(fc_mean.index, fc_conf.iloc[:,0], fc_conf.iloc[:,1], color='r', alpha=0.3)
    else:
        line_fore.set_data([], [])

    return line_hist, line_fore

# Number of frames: from start_train to total_points-1
frames = range(start_train, total_points)
anim = animation.FuncAnimation(fig, update, frames=frames, init_func=init, blit=False, repeat=False)

# Save the animation as MP4 (requires ffmpeg)
anim.save('arima_forecast_demo.mp4', writer='ffmpeg', fps=2)

plt.show()
```

**What This Code Does:**
- Loads the AirPassengers dataset.
- Iterates through the dataset month by month (from `start_train` onward).
- At each step:
  - Fits an ARIMA model to the data seen so far.
  - Forecasts the next 12 months (or fewer if near the end of data).
  - Updates the plot to show historical data, the new forecast, and the confidence intervals.
- Produces an MP4 video illustrating how the forecast evolves as more data becomes available.

**Adjustments:**
- Change ARIMA parameters `(p,d,q)` or use `auto_arima` for better model selection.
- Modify `n_forecast` or `start_train`.
- Use a different dataset or apply transformations (like differencing) before fitting ARIMA.
- Add annotations or lines to highlight changes in forecast accuracy over time.

After running the code locally, open `arima_forecast_demo.mp4` to view a conceptual demonstration of ARIMA forecasting.

----

Write a Python program for forecasting algorithms LSTM

Python program that demonstrates how to use a Long Short-Term Memory (LSTM) neural network for time series forecasting. LSTM models are a type of recurrent neural network (RNN) that can learn long-term dependencies, making them well-suited for sequential data like time series.

**Steps:**

1. Load a time series dataset (we’ll use the monthly AirPassengers dataset).
2. Preprocess the data:
   - Normalize/scale the data.
   - Convert the time series into a supervised learning problem by creating input sequences (X) and targets (y).
3. Split the data into training and testing sets.
4. Build and train an LSTM model using Keras.
5. Evaluate the model and use it to forecast future values.

- LSTM training can be resource-intensive.  
- Consider tuning hyperparameters (LSTM units, learning rate, epochs) for better performance.  
- Adjust the look-back window based on the complexity of the time series.  
- In practice, you might need more data and regularization to get good forecasts.

**Code:**

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from statsmodels.datasets import get_rdataset

# 1. Load the AirPassengers dataset
data = get_rdataset('AirPassengers', package='datasets').data
data['date'] = pd.date_range(start='1949-01-01', periods=len(data), freq='MS')
data.set_index('date', inplace=True)
ts = data['value'].astype(float).values

# Normalize the data for better model performance
scaler = MinMaxScaler(feature_range=(0, 1))
ts_scaled = scaler.fit_transform(ts.reshape(-1,1))

# 2. Create a function to convert time series into supervised format
def create_dataset(dataset, look_back=12):
    X, y = [], []
    for i in range(len(dataset)-look_back):
        X.append(dataset[i:(i+look_back), 0])
        y.append(dataset[i+look_back, 0])
    return np.array(X), np.array(y)

look_back = 12
X, y = create_dataset(ts_scaled, look_back=look_back)

# Reshape X for LSTM: (samples, timesteps, features)
X = X.reshape(X.shape[0], X.shape[1], 1)

# 3. Split into train and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# 4. Build and train the LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(look_back, 1), return_sequences=False))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)

# 5. Make predictions
train_pred = model.predict(X_train)
test_pred = model.predict(X_test)

# Inverse transform predictions
train_pred_inv = scaler.inverse_transform(train_pred)
y_train_inv = scaler.inverse_transform(y_train.reshape(-1,1))
test_pred_inv = scaler.inverse_transform(test_pred)
y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1))

# Plot the results
plt.figure(figsize=(10,6))
plt.plot(data.index, ts, label='Original Data')
# Plot train predictions
train_index = data.index[look_back:look_back+len(train_pred_inv)]
plt.plot(train_index, train_pred_inv, label='Train Predictions', color='red')
# Plot test predictions
test_index = data.index[look_back+len(train_pred_inv):look_back+len(train_pred_inv)+len(test_pred_inv)]
plt.plot(test_index, test_pred_inv, label='Test Predictions', color='green')
plt.title('LSTM Forecast of AirPassengers')
plt.xlabel('Date')
plt.ylabel('Passengers')
plt.legend()
plt.show()

# Evaluate model performance with a simple metric (e.g., RMSE on test set)
from sklearn.metrics import mean_squared_error
rmse = np.sqrt(mean_squared_error(y_test_inv, test_pred_inv))
print(f'Test RMSE: {rmse:.2f}')
```

**What This Code Does:**

- Loads and normalizes the AirPassengers dataset.
- Converts the series into a supervised learning format suitable for LSTM.
- Splits the data into train and test sets.
- Builds and trains a simple LSTM network to predict the next month’s passenger number given the previous 12 months.
- Plots the original data alongside the model’s predictions for both training and testing periods.
- Calculates a simple error metric (RMSE) for the test set predictions.

**Adjustments:**

- Change the `look_back` window size.
- Try different LSTM units or add more layers for a more complex model.
- Experiment with different epochs and batch sizes.
- Apply advanced techniques (e.g., dropout regularization) if overfitting occurs.

----

Create a video for forecasting algorithm LSTM

Python code that creates a video to demonstrate how an LSTM model forecasts a time series. This is not a fully tuned model, showing how the forecast updates as more data is revealed or as we slide a forecasting window forward.

1. Use a known time series (e.g., AirPassengers data).
2. Train a simple LSTM model once on a portion of the data.
3. Create an animation where:
   - We gradually reveal more of the test set.
   - At each frame, show how the LSTM model, given the most recent `look_back` points, predicts the next point.
   - Plot the historical data, the current known part of the test data, and the model's prediction for the next time step.
   - Over frames, we move forward through the test set, showing how the LSTM forecasts unfold step-by-step.

- This code assumes you've installed `tensorflow` and `statsmodels`.
- Requires `ffmpeg` to save the animation as MP4.
- The LSTM is trained only once before animation. The animation simulates step-by-step forecasting by using the model’s predictions as we move through the test set.
- Consider fewer epochs or a smaller dataset if training is slow.
- This is a conceptual demo, so the forecasts may not be perfect.

**Code (run locally):**

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from statsmodels.datasets import get_rdataset

# Load AirPassengers dataset
data = get_rdataset('AirPassengers', package='datasets').data
data['date'] = pd.date_range(start='1949-01-01', periods=len(data), freq='MS')
data.set_index('date', inplace=True)
ts = data['value'].astype(float).values

# Normalize the data
scaler = MinMaxScaler(feature_range=(0,1))
ts_scaled = scaler.fit_transform(ts.reshape(-1,1))

# Prepare supervised data
def create_dataset(dataset, look_back=12):
    X, y = [], []
    for i in range(len(dataset)-look_back):
        X.append(dataset[i:i+look_back, 0])
        y.append(dataset[i+look_back, 0])
    return np.array(X), np.array(y)

look_back = 12
X_all, y_all = create_dataset(ts_scaled, look_back=look_back)

# Split into train and test
train_size = int(len(X_all)*0.8)
X_train, X_test = X_all[:train_size], X_all[train_size:]
y_train, y_test = y_all[:train_size], y_all[train_size:]

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build and train LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(look_back,1)))
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')
model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=1)

# We'll animate step-by-step forecasting on the test set
fig, ax = plt.subplots(figsize=(10,6))
ax.set_title("LSTM Forecast Animation")
ax.set_xlabel("Time")
ax.set_ylabel("Passengers")
ax.plot(data.index, ts, label='Original Data', color='blue', alpha=0.3)

# We'll plot the train data and test data points revealed so far
line_train, = ax.plot(data.index[:train_size+look_back], ts[:train_size+look_back], 'b-', label='Training Data')
line_test, = ax.plot([], [], 'g-', label='Test Data (Revealed)')
point_fore, = ax.plot([], [], 'ro', label='Forecast Next Point')

ax.legend()

def init():
    ax.set_xlim(data.index[0], data.index[-1])
    # y-limits
    y_min, y_max = ts.min(), ts.max()
    ax.set_ylim(y_min-50, y_max+200)
    return line_train, line_test, point_fore

def update(frame):
    # frame: 0 to len(X_test)-1
    # Revealed test data up to frame
    revealed = ts[train_size+look_back:train_size+look_back+frame+1]
    revealed_idx = data.index[train_size+look_back:train_size+look_back+frame+1]

    line_test.set_data(revealed_idx, revealed)

    # Prepare last window for forecasting
    last_window = ts_scaled[train_size+frame:train_size+frame+look_back]  # last look_back points
    last_window = last_window.reshape(1, look_back, 1)
    forecast_scaled = model.predict(last_window)[0,0]
    forecast_val = scaler.inverse_transform([[forecast_scaled]])[0,0]

    # The forecast is for the next point after the revealed portion
    next_time = data.index[train_size+look_back+frame+1] if (train_size+look_back+frame+1)<len(data) else data.index[-1]
    point_fore.set_data(next_time, forecast_val)

    return line_train, line_test, point_fore

frames = len(X_test)
anim = animation.FuncAnimation(fig, update, frames=frames, init_func=init, blit=False, repeat=False)

# Save animation as MP4 (requires ffmpeg)
anim.save('lstm_forecast_demo.mp4', writer='ffmpeg', fps=2)

plt.show()
```

**What This Code Does:**

- Trains an LSTM model on the training portion of the AirPassengers dataset.
- Creates an animation where we move through the test set point by point:
  - Each frame reveals one more test data point.
  - The LSTM model forecasts the next point after the revealed data.
  - Plots the forecast as a red point and updates as we move forward in time.
- By watching the animation, you can see how the LSTM predicts upcoming points as new observed data becomes available, illustrating the forecasting process over time.

**Adjustments:**

- Increase epochs or units in LSTM for better performance (might slow down training).
- Change the `look_back` window.
- Use different datasets or apply more complex architectures.

After running the code locally, open `lstm_forecast_demo.mp4` to see a conceptual demonstration of step-by-step LSTM forecasting.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c84c44-bcef-4309-bef7-ce3520925739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: langchain-core 0.3.28\n",
      "Uninstalling langchain-core-0.3.28:\n",
      "  Successfully uninstalled langchain-core-0.3.28\n",
      "Found existing installation: langchain-openai 0.2.1\n",
      "Uninstalling langchain-openai-0.2.1:\n",
      "  Successfully uninstalled langchain-openai-0.2.1\n",
      "Found existing installation: langchain-experimental 0.3.2\n",
      "Uninstalling langchain-experimental-0.3.2:\n",
      "  Successfully uninstalled langchain-experimental-0.3.2\n",
      "Found existing installation: langchain-community 0.3.1\n",
      "Uninstalling langchain-community-0.3.1:\n",
      "  Successfully uninstalled langchain-community-0.3.1\n",
      "Found existing installation: langchain 0.3.1\n",
      "Uninstalling langchain-0.3.1:\n",
      "  Successfully uninstalled langchain-0.3.1\n",
      "Found existing installation: chromadb 0.5.11\n",
      "Uninstalling chromadb-0.5.11:\n",
      "  Successfully uninstalled chromadb-0.5.11\n",
      "\u001b[33mWARNING: Skipping beautifulsoup4 as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: python-dotenv 1.0.1\n",
      "Uninstalling python-dotenv-1.0.1:\n",
      "  Successfully uninstalled python-dotenv-1.0.1\n",
      "Found existing installation: PyPDF2 3.0.1\n",
      "Uninstalling PyPDF2-3.0.1:\n",
      "  Successfully uninstalled PyPDF2-3.0.1\n",
      "Found existing installation: rank-bm25 0.2.2\n",
      "Uninstalling rank-bm25-0.2.2:\n",
      "  Successfully uninstalled rank-bm25-0.2.2\n",
      "\u001b[33mWARNING: Skipping ragas as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: tqdm 4.67.1\n",
      "Uninstalling tqdm-4.67.1:\n",
      "  Successfully uninstalled tqdm-4.67.1\n",
      "Found existing installation: matplotlib 3.10.0\n",
      "Uninstalling matplotlib-3.10.0:\n",
      "  Successfully uninstalled matplotlib-3.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-core==0.3.6\n",
      "  Using cached langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core==0.3.6) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.6) (2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (3.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.6) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.6) (2.27.2)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (1.0.2)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (2.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6) (1.3.0)\n",
      "Using cached langchain_core-0.3.6-py3-none-any.whl (399 kB)\n",
      "Installing collected packages: langchain-core\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-text-splitters 0.3.4 requires langchain-core<0.4.0,>=0.3.26, but you have langchain-core 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-openai==0.2.1\n",
      "  Using cached langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-openai==0.2.1) (0.3.6)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-openai==0.2.1) (1.57.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-openai==0.2.1) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (1.3.0)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.1) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.1) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (3.6)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.1) (2.1.0)\n",
      "Using cached langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, langchain-openai\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.27.0 requires matplotlib~=3.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-openai-0.2.1 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-experimental==0.3.2\n",
      "  Using cached langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental==0.3.2)\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-experimental==0.3.2) (0.3.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.4.0)\n",
      "Collecting langchain<0.4.0,>=0.3.13 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Using cached langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain-experimental==0.3.2)\n",
      "  Using cached langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.1.147)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (2.10.4)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (2.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.13->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.3.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (2.27.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2023.11.17)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.3.0)\n",
      "Using cached langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
      "Using cached langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
      "Using cached langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, langchain-core, langchain, langchain-community, langchain-experimental\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.6\n",
      "    Uninstalling langchain-core-0.3.6:\n",
      "      Successfully uninstalled langchain-core-0.3.6\n",
      "Successfully installed langchain-0.3.13 langchain-community-0.3.13 langchain-core-0.3.28 langchain-experimental-0.3.2 python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-community==0.3.1\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.3.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.3.28)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.1.147)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community==0.3.1) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (2.10.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.1) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (2023.11.17)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (1.3.0)\n",
      "Using cached langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "Installing collected packages: langchain-community\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.13\n",
      "    Uninstalling langchain-community-0.3.13:\n",
      "      Successfully uninstalled langchain-community-0.3.13\n",
      "Successfully installed langchain-community-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain==0.3.1\n",
      "  Using cached langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (0.3.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (0.3.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (0.1.147)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain==0.3.1) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (2023.11.17)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (2.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (1.3.0)\n",
      "Using cached langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "Installing collected packages: langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.13\n",
      "    Uninstalling langchain-0.3.13:\n",
      "      Successfully uninstalled langchain-0.3.13\n",
      "Successfully installed langchain-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb==0.5.11\n",
      "  Using cached chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.0.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (2.10.4)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.108.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (3.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (1.68.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from chromadb==0.5.11) (13.7.0)\n",
      "Requirement already satisfied: packaging>=19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from build>=1.0.3->chromadb==0.5.11) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from build>=1.0.3->chromadb==0.5.11) (1.0.0)\n",
      "Requirement already satisfied: starlette<0.33.0,>=0.29.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb==0.5.11) (0.32.0.post1)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (1.0.2)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.11) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.37.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (1.7.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.1.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.11) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.11) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.11) (5.29.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.5.11) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.11) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.11) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.11) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.11) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.11) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11) (0.50b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11) (1.17.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.5.11) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.5.11) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.5.11) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.5.11) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich>=10.11.0->chromadb==0.5.11) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich>=10.11.0->chromadb==0.5.11) (2.17.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb==0.5.11) (0.27.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.5.11) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.5.11) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (11.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11) (4.9)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.5.11) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.5.11) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.11) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.11) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb==0.5.11) (3.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb==0.5.11) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.11) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.11) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11) (0.6.1)\n",
      "Using cached chromadb-0.5.11-py3-none-any.whl (603 kB)\n",
      "Installing collected packages: chromadb\n",
      "Successfully installed chromadb-0.5.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: uvloop 0.19.0\n",
      "Uninstalling uvloop-0.19.0:\n",
      "  Successfully uninstalled uvloop-0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting rank_bm25==0.2.2\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rank_bm25==0.2.2) (1.26.4)\n",
      "Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ragas==0.1.20\n",
      "  Downloading ragas-0.1.20-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (1.26.4)\n",
      "Collecting datasets (from ragas==0.1.20)\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (0.8.0)\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (0.3.1)\n",
      "Collecting langchain-core<0.3 (from ragas==0.1.20)\n",
      "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (0.3.1)\n",
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (0.2.1)\n",
      "Requirement already satisfied: openai>1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (1.57.4)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.1.20)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ragas==0.1.20) (1.5.8)\n",
      "Collecting appdirs (from ragas==0.1.20)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3->ragas==0.1.20) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>1->ragas==0.1.20) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>1->ragas==0.1.20) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>1->ragas==0.1.20) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>1->ragas==0.1.20) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>1->ragas==0.1.20) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai>1->ragas==0.1.20) (4.67.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets->ragas==0.1.20) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->ragas==0.1.20)\n",
      "  Using cached pyarrow-18.1.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.1.20)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets->ragas==0.1.20) (2.2.3)\n",
      "Collecting requests>=2.32.2 (from datasets->ragas==0.1.20)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets->ragas==0.1.20)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas==0.1.20)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas==0.1.20)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets->ragas==0.1.20) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets->ragas==0.1.20) (0.27.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->ragas==0.1.20) (2.0.36)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain (from ragas==0.1.20)\n",
      "  Using cached langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Using cached langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain->ragas==0.1.20)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community->ragas==0.1.20) (0.6.7)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community (from ragas==0.1.20)\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community->ragas==0.1.20) (0.4.0)\n",
      "  Using cached langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->ragas==0.1.20)\n",
      "  Downloading SQLAlchemy-2.0.35-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting langchain-community (from ragas==0.1.20)\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai (from ragas==0.1.20)\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken->ragas==0.1.20) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets->ragas==0.1.20) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.20) (3.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.20) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.20) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.20) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.20) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.1.20) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3->ragas==0.1.20) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3->ragas==0.1.20) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3->ragas==0.1.20) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3->ragas==0.1.20) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3->ragas==0.1.20) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets->ragas==0.1.20) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets->ragas==0.1.20) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets->ragas==0.1.20) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets->ragas==0.1.20) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets->ragas==0.1.20) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.1.20) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.20) (1.0.0)\n",
      "Downloading ragas-0.1.20-py3-none-any.whl (190 kB)\n",
      "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
      "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading langchain-0.2.17-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.2.19-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached pyarrow-18.1.0-cp312-cp312-macosx_12_0_arm64.whl (29.5 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: appdirs, xxhash, requests, pysbd, pyarrow, fsspec, dill, multiprocess, langchain-core, datasets, langchain-text-splitters, langchain-openai, langchain, langchain-community, ragas\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.28\n",
      "    Uninstalling langchain-core-0.3.28:\n",
      "      Successfully uninstalled langchain-core-0.3.28\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.4\n",
      "    Uninstalling langchain-text-splitters-0.3.4:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.4\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.2.1\n",
      "    Uninstalling langchain-openai-0.2.1:\n",
      "      Successfully uninstalled langchain-openai-0.2.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.1\n",
      "    Uninstalling langchain-0.3.1:\n",
      "      Successfully uninstalled langchain-0.3.1\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.1\n",
      "    Uninstalling langchain-community-0.3.1:\n",
      "      Successfully uninstalled langchain-community-0.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.27.0 requires matplotlib~=3.0, which is not installed.\n",
      "langchain-experimental 0.3.2 requires langchain-community<0.4.0,>=0.3.0, but you have langchain-community 0.2.19 which is incompatible.\n",
      "langchain-experimental 0.3.2 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.2.43 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 langchain-0.2.17 langchain-community-0.2.19 langchain-core-0.2.43 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 multiprocess-0.70.16 pyarrow-18.1.0 pysbd-0.3.4 ragas-0.1.20 requests-2.32.3 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/Users/bparanj/Library/Python/3.12/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.27.0 requires matplotlib~=3.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib==3.9.2\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib==3.9.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "\n",
    "# Uninstall conflicting packages\n",
    "%pip uninstall -y langchain-core langchain-openai langchain-experimental langchain-community langchain chromadb beautifulsoup4 python-dotenv PyPDF2 rank_bm25 ragas tqdm matplotlib \n",
    "\n",
    "# Install compatible versions of langchain-core and langchain-openai\n",
    "%pip install langchain-core==0.3.6\n",
    "%pip install langchain-openai==0.2.1\n",
    "%pip install langchain-experimental==0.3.2\n",
    "%pip install langchain-community==0.3.1\n",
    "%pip install langchain==0.3.1\n",
    "\n",
    "# Install remaining packages\n",
    "%pip install chromadb==0.5.11\n",
    "%pip install python-dotenv==1.0.1\n",
    "%pip uninstall uvloop -y\n",
    "%pip install PyPDF2==3.0.1 -q --user\n",
    "%pip install rank_bm25==0.2.2\n",
    "\n",
    "# new\n",
    "%pip install ragas==0.1.20\n",
    "%pip install tqdm==4.66.5 -q --user\n",
    "%pip install matplotlib==3.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bf2469-624b-4d48-b270-522c23e92819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USER_AGENT'] = 'RAGUserAgent'\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "## new\n",
    "import tqdm as notebook_tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6473c1-c64c-4ee8-8719-3221212969e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "pdf_path = \"google-2023-environmental-report.pdf\"\n",
    "collection_name = \"google_environmental_report\"\n",
    "str_output_parser = StrOutputParser()\n",
    "user_query = \"What are Google's environmental initiatives?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1ede4d-6e62-43c5-8e51-90f4c5dc8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_ada = \"text-embedding-ada-002\"\n",
    "model_gpt35=\"gpt-3.5-turbo\"\n",
    "model_gpt4=\"gpt-4o-mini\"\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=embedding_ada, openai_api_key=openai.api_key)\n",
    "llm = ChatOpenAI(model=model_gpt35, openai_api_key=openai.api_key, temperature=0.0)\n",
    "generator_llm = ChatOpenAI(model=model_gpt35, openai_api_key=openai.api_key, temperature=0.0)\n",
    "critic_llm = ChatOpenAI(model=model_gpt4, openai_api_key=openai.api_key, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f972b30-3781-41f8-bbd6-4bafad2fba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = PdfReader(pdf_path)\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13082493-19dd-4141-9f62-25bf8ae573b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "splits = character_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb57152-f065-42e7-b672-bddfcbdba13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_documents = [Document(page_content=text, metadata={\"id\": str(i), \"source\": \"dense\"}) for i, text in enumerate(splits)]\n",
    "sparse_documents = [Document(page_content=text, metadata={\"id\": str(i), \"source\": \"sparse\"}) for i, text in enumerate(splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4814bdc-2fd1-40c4-8960-58ecedbd5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=dense_documents,\n",
    "    embedding=embedding_function,\n",
    "    collection_name=collection_name,\n",
    "    client=chroma_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ffc0b3-f7b2-4b8c-bbcb-b6e78c3224bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "sparse_retriever = BM25Retriever.from_documents(sparse_documents, k=10)\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[dense_retriever, sparse_retriever], weights=[0.5, 0.5], c=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d0d2ed-aa81-4e85-8935-e918fde7fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"jclemens24/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f897ef0-98e6-4e16-970b-ada0a6f1d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Given the following question and retrieved context, determine if the context is relevant to the question.\n",
    "    Provide a score from 1 to 5, where 1 is not at all relevant and 5 is highly relevant.\n",
    "    Return ONLY the numeric score, without any additional text or explanation.\n",
    "\n",
    "    Question: {question}\n",
    "    Retrieved Context: {retrieved_context}\n",
    "\n",
    "    Relevance Score:\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeff1c5e-49aa-40e3-9208-de837f397b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986d3049-2a2b-4df4-adfa-6599911918be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(llm_output):\n",
    "    try:\n",
    "        score = float(llm_output.strip())\n",
    "        return score\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "# Chain it all together with LangChain\n",
    "def conditional_answer(x):\n",
    "    relevance_score = extract_score(x['relevance_score'])\n",
    "    if relevance_score < 4:\n",
    "        return \"I don't know.\"\n",
    "    else:\n",
    "        return x['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debdce13-0aad-44ff-aa79-97e720559139",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | RunnableParallel(\n",
    "        {\"relevance_score\": (\n",
    "            RunnablePassthrough()\n",
    "            | (lambda x: relevance_prompt_template.format(question=x['question'], retrieved_context=x['context']))\n",
    "            | llm\n",
    "            | str_output_parser\n",
    "        ), \"answer\": (\n",
    "            RunnablePassthrough()\n",
    "            | prompt\n",
    "            | llm\n",
    "            | str_output_parser\n",
    "        )}\n",
    "    )\n",
    "    | RunnablePassthrough().assign(final_answer=conditional_answer)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5adcab85-5d8e-4703-bb05-c47b6e7506c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_similarity = RunnableParallel(\n",
    "    {\"context\": dense_retriever,\n",
    "     \"question\": RunnablePassthrough()\n",
    "}).assign(answer=rag_chain_from_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad3a4bfa-d0bb-4548-a787-a2af5327f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_hybrid = RunnableParallel(\n",
    "    {\"context\": ensemble_retriever,\n",
    "     \"question\": RunnablePassthrough()\n",
    "}).assign(answer=rag_chain_from_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a332cc42-058e-482e-a0fb-253c402960f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question to Similarity Search: What are Google's environmental initiatives?\n",
      "\n",
      "Relevance Score: 5\n",
      "\n",
      "Final Answer:\n",
      "Google's environmental initiatives include empowering individuals to take action, working together with partners and customers, operating sustainably, achieving net-zero carbon emissions, water stewardship, and promoting a circular economy. They have implemented sustainability features in products like Google Maps, Google Nest thermostats, and Google Flights to help individuals make more sustainable choices. Google is also involved in public policy advocacy, supporting initiatives like the iMasons Climate Accord, ReFED, and The Nature Conservancy. Additionally, Google is a member of organizations like the World Business Council for Sustainable Development and the World Resources Institute to collaborate on sustainability projects.\n",
      "\n",
      "\n",
      "Retrieved Documents:\n",
      "Document 1: Document ID: 451 source: dense\n",
      "Content:\n",
      "Empowering individuals:  \n",
      "A parking lot full of electric vehicles lined up outside a Google office, \n",
      "plugged into charging stations.\n",
      "Working together:  \n",
      "Satellite-derived Earth Engine image showing seasonal agricultural peaks \n",
      "near the Columbia and Snake Rivers in Washington state. The perfectly round fields are center pivot irrigated corn and wheat maturing in different months. Data source: Landsat 8, U.S. Geological Survey.\n",
      "Operating sustainably:  \n",
      "A view of our Bay View campus with the events center in the foreground \n",
      "and a Google brandmark sculpture. (Photo: Iwan Baan)\n",
      "Net-zero carbon:  \n",
      "Golden Hills wind farm in California (43 MW for Google)\n",
      "Water stewardship:  \n",
      "Our Bay View campus, as seen from across its stormwater retention pond. (Photo: Iwan Baan)\n",
      "Circular economy:  \n",
      "A closeup of many small, broken circuit boards in a pile. Our approach\n",
      "\n",
      "Document 2: Document ID: 12 source: dense\n",
      "Content:\n",
      "The opportunity we have through our products and \n",
      "platforms is reflected in our updated environmental sustainability strategy, which focuses on where we can make the most significant positive impact. Our work is organized around three key pillars: empowering individuals to take action, working together with our partners and customers, and operating our businesssustainably.\n",
      "In 2022, we reached our goal to help 1 billion people \n",
      "make more sustainable choices through our products. We achieved this by offering sustainability features like eco-friendly routing in Google Maps, energy efficiency features in Google Nest thermostats, and carbon emissions information in Google Flights. Looking ahead, our aspiration is to help individuals, cities, and other partners collectively reduce 1 gigaton of their carbon equivalent emissions annually by 2030.\n",
      "2\n",
      "\n",
      "Document 3: Document ID: 311 source: dense\n",
      "Content:\n",
      "In 2022, we audited a subset of our suppliers to verify \n",
      "compliance for the following environmental criteria: implementation of environmental management systems, environmental permits and reporting, product content restrictions, and resource efficiency, as well as management of hazardous substances, wastewater,  solid waste, and air emissions.\n",
      "Googlers chat among indoor plants at our Pier 57 office in New York City.   79\n",
      "2023 Environmental Report  Public policy and advocacy\n",
      "We know that strong public policy action is critical to \n",
      "creating prosperous, equitable, and resilient low-carbon economies around the world. \n",
      "The United Nations Framework Convention on Climate \n",
      "Change (UNFCCC)s 2015 Paris Agreement states that humanity must keep global temperature rise this century well below 2C above pre-industrial levels.\n",
      "143 Google\n",
      "\n",
      "Document 4: Document ID: 344 source: dense\n",
      "Content:\n",
      "iMasons Climate AccordGoogle is a founding member and part of the governing body of the iMasons Climate Accord, a coalition united on carbon reduction in digital infrastructure.\n",
      "ReFEDIn 2022, to activate industry-wide change, Google provided anchor funding to kickstart the ReFED Catalytic Grant Fund, with the goal of accelerating and scaling food waste solutions.\n",
      "The Nature Conservancy (TNC)In 2022, Google supported three of the Nature Conservancys watershed projects in Chile and the United States, and Google.org supported a three-phased approach to catalyze active reforestation of kelp at impactful scales. Google.org also provided a grant to TNC to develop a machine-learning-powered timber-tracing API to stop deforestation in the Amazon at scale; a team of Google engineers is working full-time for six months with TNC to develop this product as part of the Google.org Fellowship Program.\n",
      "\n",
      "Document 5: Document ID: 13 source: dense\n",
      "Content:\n",
      "2\n",
      "After two years of condensed reporting, were sharing a deeper dive into our approach in one place in our 2023 Environmental Report. In 2022, we continued to make measurable progress in many key ways, such as:\n",
      " We enhanced and launched new sustainabilityproduct features , such as eco-friendly routing in\n",
      "Maps, which is estimated to have helped preventmore than 1.2 million metric tons of carbon emissionsfrom launch through 2022equivalent to takingapproximately 250,000 fuel-based cars off the roadfor a year.\n",
      "3\n",
      " We expanded the availability of Google EarthEngine which provides access to reliable, up-to-\n",
      "date insights on how our planet is changingtoinclude businesses and governments worldwide as anenterprise-grade service through Google Cloud. We opened our new Bay View campus , which is\n",
      "all-electric, net water-positive, restores over 17 acresof high-value nature, and incorporates the leadingprinciples of circular design.\n",
      "\n",
      "Document 6: Document ID: 115 source: dense\n",
      "Content:\n",
      "of over 140 partner organizations.\n",
      "The Google.org Impact Challenge on Climate Innovation supports breakthrough projects that use data and technology to \n",
      "accelerate climate action.\n",
      "The journey ahead\n",
      "From measuring and monitoring changes on the Earths surface, improving forecast and prediction models for flooding and wildfires, optimizing operations, combining disparate data sources, and designing more efficient products, we continue to leverage our expertise in technology and apply the latest advancements to help solve global challenges.\n",
      "We believe that by working together with our partners and \n",
      "customers, we can make a real difference in addressing the challenges of climate change and ecosystem degradation. LEARN MORE\n",
      " Data Commons\n",
      " Environmental Insights Explorer\n",
      " Google Cloud sustainability\n",
      " Google Earth Engine\n",
      " Sustainability-focused accelerators   31\n",
      "2023 Environmental Report  Operating \n",
      "sustainably\n",
      "Were showing the way forward \n",
      "through our own operationsOur ambition\n",
      "\n",
      "Document 7: Document ID: 346 source: dense\n",
      "Content:\n",
      "World Business Council for Sustainable Development (WBCSD)Google has been a member of the WBCSD for several years and participates in a number of its initiatives. \n",
      "Were a\n",
      "ctively involved in initiatives related to improving well-being for people and the planet, including  \n",
      "shifting diets, consumer behavior changes, and regenerative agriculture. \n",
      "World Resources Institute (WRI)Google has a 13-year long relationship with WRI for impact-focused collaboration. Some key projects include developing a near-real-time land cover dataset ( Dynamic World ), deforestation monitoring and alerts ( Global \n",
      "Forest Watch ), ending commodity-driven deforestation and accelerating restoration ( Forest Data Partnership ), \n",
      "measuring and mitigating extreme heat ( supported by Google.org ), and educating stakeholders on 24/7 CFE.   84\n",
      "2023 Environmental Report  Awards and recognition\n",
      "2022 CDP Climate Change A List  \n",
      "Alphabet has been named to CDPs Climate Change A list,\n",
      "\n",
      "Document 8: Document ID: 67 source: dense\n",
      "Content:\n",
      "Our approach\n",
      "Supporting partners\n",
      "Investing in breakthrough \n",
      "innovation\n",
      "Creating ecosystems for \n",
      "collaboration\n",
      "The journey ahead\n",
      "   21\n",
      "2023 Environmental Report  Our ambition\n",
      "We believe that Google has a unique \n",
      "opportunity that extends beyond reducing \n",
      "the environmental impacts of our own \n",
      "operations and value chain. By organizing \n",
      "information about our planet and making \n",
      "it actionable through technology and \n",
      "platforms, we can help partners and \n",
      "customers create even more positive impact.\n",
      "Digital technologies  play a critical role in industry \n",
      "transitions, allowing us to measure and track sustainability \n",
      "progress, optimize the use of resources, reduce \n",
      "greenhouse gas emissions, and enable a more circular \n",
      "economy.50 Cloud computing and digital technologies \n",
      "underpin the transformation in many sectors, such as \n",
      "energy, transportation, and agriculture. Research  that \n",
      "we commissioned in 2022 found that 20%25% of whats \n",
      "required for the EUs 2050 net-zero goal requires some\n",
      "\n",
      "Document 9: Document ID: 66 source: dense\n",
      "Content:\n",
      "the United States for pre-owned products, such as used and refurbished products. The journey \n",
      "ahead\n",
      "While a single individuals actions may seem small, when \n",
      "billions of people have the tools to make more sustainable decisions, they add up to have a meaningful impact on their communities and the entire planet. \n",
      "Were excited by the opportunity to enable climate and \n",
      "environmental action far beyond Googles direct impact, through information and innovation.\n",
      "LEARN MORE\n",
      "  Empowering with technology\n",
      "  Google Maps eco-friendly routing\n",
      "  Searching for sustainability with Google\n",
      "  Supporting a clean energy future with Nest Renew\n",
      "  The search for sustainability   20\n",
      "2023 Environmental Report  Working \n",
      "together\n",
      "Were working together with our \n",
      "partners and customers to advance technology for sustainabilityOur ambition\n",
      "Our approach\n",
      "Supporting partners\n",
      "Investing in breakthrough \n",
      "innovation\n",
      "Creating ecosystems for \n",
      "collaboration\n",
      "The journey ahead\n",
      "   21\n",
      "2023 Environmental Report  Our ambition\n",
      "\n",
      "Document 10: Document ID: 262 source: dense\n",
      "Content:\n",
      "135 \n",
      "Preserving nature is critical both to mitigating climate  \n",
      "change and adapting to it. We want nature and people to flourish together in the communities that Google calls  home, as well as the ecosystems where we source food  for the hundreds of cafes we operate. Our approach\n",
      "We strive to protect and enhance nature and biodiversity through our campuses and technology.\n",
      "Google has offices in nearly 60 countries around the world \n",
      "(as of year-end 2022). In these locations, we aim to protect and enhance nature and biodiversity through a four-pillar approach that starts with building biodiversity at our own office and campus developments, as well as protecting nature and making it more accessible in the surrounding communities where we operate (see Figure 24).\n",
      "Our approach further focuses on sourcing responsibly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain_similarity.invoke(user_query)\n",
    "retrieved_docs = result['context']\n",
    "\n",
    "print(f\"Original Question to Similarity Search: {user_query}\\n\")\n",
    "print(f\"Relevance Score: {result['answer']['relevance_score']}\\n\")\n",
    "print(f\"Final Answer:\\n{result['answer']['final_answer']}\\n\\n\")\n",
    "print(\"Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"Document {i}: Document ID: {doc.metadata['id']} source: {doc.metadata['source']}\")\n",
    "    print(f\"Content:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7732c5f6-295f-4589-a28c-2ec117cdc336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question to Dense Search: What are Google's environmental initiatives?\n",
      "\n",
      "Relevance Score: 5\n",
      "\n",
      "Final Answer:\n",
      "Google's environmental initiatives include empowering individuals to take action, working together with partners and customers, operating sustainably, achieving net-zero carbon emissions, focusing on water stewardship, engaging in a circular economy, and supporting sustainable consumption of public goods. They also engage with suppliers to reduce energy consumption and greenhouse gas emissions, report environmental data, and assess environmental criteria. Google is involved in various sustainability initiatives and coalitions, such as the iMasons Climate Accord, ReFED, and The Nature Conservancy. They also work with organizations like the World Business Council for Sustainable Development and the World Resources Institute. Additionally, Google is focused on renewable energy, data center efficiency, and using technology to drive sustainability progress.\n",
      "\n",
      "\n",
      "Retrieved Documents:\n",
      "Document 1: Document ID: 451 source: dense\n",
      "Content:\n",
      "Empowering individuals:  \n",
      "A parking lot full of electric vehicles lined up outside a Google office, \n",
      "plugged into charging stations.\n",
      "Working together:  \n",
      "Satellite-derived Earth Engine image showing seasonal agricultural peaks \n",
      "near the Columbia and Snake Rivers in Washington state. The perfectly round fields are center pivot irrigated corn and wheat maturing in different months. Data source: Landsat 8, U.S. Geological Survey.\n",
      "Operating sustainably:  \n",
      "A view of our Bay View campus with the events center in the foreground \n",
      "and a Google brandmark sculpture. (Photo: Iwan Baan)\n",
      "Net-zero carbon:  \n",
      "Golden Hills wind farm in California (43 MW for Google)\n",
      "Water stewardship:  \n",
      "Our Bay View campus, as seen from across its stormwater retention pond. (Photo: Iwan Baan)\n",
      "Circular economy:  \n",
      "A closeup of many small, broken circuit boards in a pile. Our approach\n",
      "\n",
      "Document 2: Document ID: 150 source: sparse\n",
      "Content:\n",
      "sustainability, and were partnering with them to develop decarbonization roadmaps and build essential data infrastructure to accurately quantify emissions and reductions across the value chain.\n",
      "We engage with our suppliersincluding hardware \n",
      "manufacturing and indirect services suppliersto help reduce their energy consumption and GHG emissions, as stated in our Supplier Code of Conduct , which all \n",
      "suppliers are required to sign. We assess suppliers practices to report, manage, and reduce their emissions and incorporate this into our supplier scorecard.\n",
      "Reporting  \n",
      "environmental data\n",
      "We expect all our suppliers to report environmental data,\n",
      "\n",
      "Document 3: Document ID: 311 source: dense\n",
      "Content:\n",
      "In 2022, we audited a subset of our suppliers to verify \n",
      "compliance for the following environmental criteria: implementation of environmental management systems, environmental permits and reporting, product content restrictions, and resource efficiency, as well as management of hazardous substances, wastewater,  solid waste, and air emissions.\n",
      "Googlers chat among indoor plants at our Pier 57 office in New York City.   79\n",
      "2023 Environmental Report  Public policy and advocacy\n",
      "We know that strong public policy action is critical to \n",
      "creating prosperous, equitable, and resilient low-carbon economies around the world. \n",
      "The United Nations Framework Convention on Climate \n",
      "Change (UNFCCC)s 2015 Paris Agreement states that humanity must keep global temperature rise this century well below 2C above pre-industrial levels.\n",
      "143 Google\n",
      "\n",
      "Document 4: Document ID: 12 source: dense\n",
      "Content:\n",
      "The opportunity we have through our products and \n",
      "platforms is reflected in our updated environmental sustainability strategy, which focuses on where we can make the most significant positive impact. Our work is organized around three key pillars: empowering individuals to take action, working together with our partners and customers, and operating our businesssustainably.\n",
      "In 2022, we reached our goal to help 1 billion people \n",
      "make more sustainable choices through our products. We achieved this by offering sustainability features like eco-friendly routing in Google Maps, energy efficiency features in Google Nest thermostats, and carbon emissions information in Google Flights. Looking ahead, our aspiration is to help individuals, cities, and other partners collectively reduce 1 gigaton of their carbon equivalent emissions annually by 2030.\n",
      "2\n",
      "\n",
      "Document 5: Document ID: 309 source: sparse\n",
      "Content:\n",
      "that enable us to ensure that those we partner with are responsible environmental stewards. Along with having suppliers evaluate their operations, we perform our own ongoing due diligence and audits to verify compliance and to understand our supply chains current and potential risks.\n",
      "When we find that a supplier isnt complying, we expect\n",
      "\n",
      "Document 6: Document ID: 298 source: sparse\n",
      "Content:\n",
      "2023 Environmental Report  Risk management\n",
      "Our Enterprise Risk Management (ERM) team is responsible \n",
      "for identifying, assessing, and reporting risks related to the companys operations, financial performance, and reputation. As with financial, operational, and strategic risks, the team assesses environmental risks as part of the companys overall risk management framework. The risks and opportunities identified through this process support public disclosures and inform Googles environmental sustainability strategy. Our Chief Sustainability Officer and sustainability teams work to address risks by identifying opportunities to reduce the companys environmental impacts from its operations and value chain, and through improving climate resilience. \n",
      "Climate-related \n",
      "risks\n",
      "Climate-related risks and opportunities have long time\n",
      "\n",
      "Document 7: Document ID: 344 source: dense\n",
      "Content:\n",
      "iMasons Climate AccordGoogle is a founding member and part of the governing body of the iMasons Climate Accord, a coalition united on carbon reduction in digital infrastructure.\n",
      "ReFEDIn 2022, to activate industry-wide change, Google provided anchor funding to kickstart the ReFED Catalytic Grant Fund, with the goal of accelerating and scaling food waste solutions.\n",
      "The Nature Conservancy (TNC)In 2022, Google supported three of the Nature Conservancys watershed projects in Chile and the United States, and Google.org supported a three-phased approach to catalyze active reforestation of kelp at impactful scales. Google.org also provided a grant to TNC to develop a machine-learning-powered timber-tracing API to stop deforestation in the Amazon at scale; a team of Google engineers is working full-time for six months with TNC to develop this product as part of the Google.org Fellowship Program.\n",
      "\n",
      "Document 8: Document ID: 13 source: dense\n",
      "Content:\n",
      "2\n",
      "After two years of condensed reporting, were sharing a deeper dive into our approach in one place in our 2023 Environmental Report. In 2022, we continued to make measurable progress in many key ways, such as:\n",
      " We enhanced and launched new sustainabilityproduct features , such as eco-friendly routing in\n",
      "Maps, which is estimated to have helped preventmore than 1.2 million metric tons of carbon emissionsfrom launch through 2022equivalent to takingapproximately 250,000 fuel-based cars off the roadfor a year.\n",
      "3\n",
      " We expanded the availability of Google EarthEngine which provides access to reliable, up-to-\n",
      "date insights on how our planet is changingtoinclude businesses and governments worldwide as anenterprise-grade service through Google Cloud. We opened our new Bay View campus , which is\n",
      "all-electric, net water-positive, restores over 17 acresof high-value nature, and incorporates the leadingprinciples of circular design.\n",
      "\n",
      "Document 9: Document ID: 328 source: sparse\n",
      "Content:\n",
      "Sustainable \n",
      "consumption of \n",
      "public goods (e.g., \n",
      "right to repair)Google submitted comments to the European Commissions public consultation regarding \n",
      "the promotion of repair and reuse of goods. We shared our views on the core principles to \n",
      "consider when introducing policy measures to promote repair and reuse horizontally, and for \n",
      "smartphones and tablets specifically.\n",
      "Body of European \n",
      "Regulators \n",
      "for Electronic \n",
      "Communications \n",
      "(BEREC)Google responded to a questionnaire  by BEREC in view of the development of key performance \n",
      "indicators to characterize the environmental impact of electronic communications, networks, \n",
      "devices, and services. We provided information about our environmental reporting practices \n",
      "and suggestions to help identify which indicators would provide relevant environmental \n",
      "information.\n",
      "Engagement with coalitions and sustainability initiatives\n",
      "RE-Source PlatformGoogle is a strategic partner and steering committee member of the RE-Source Platform, the\n",
      "\n",
      "Document 10: Document ID: 115 source: dense\n",
      "Content:\n",
      "of over 140 partner organizations.\n",
      "The Google.org Impact Challenge on Climate Innovation supports breakthrough projects that use data and technology to \n",
      "accelerate climate action.\n",
      "The journey ahead\n",
      "From measuring and monitoring changes on the Earths surface, improving forecast and prediction models for flooding and wildfires, optimizing operations, combining disparate data sources, and designing more efficient products, we continue to leverage our expertise in technology and apply the latest advancements to help solve global challenges.\n",
      "We believe that by working together with our partners and \n",
      "customers, we can make a real difference in addressing the challenges of climate change and ecosystem degradation. LEARN MORE\n",
      " Data Commons\n",
      " Environmental Insights Explorer\n",
      " Google Cloud sustainability\n",
      " Google Earth Engine\n",
      " Sustainability-focused accelerators   31\n",
      "2023 Environmental Report  Operating \n",
      "sustainably\n",
      "Were showing the way forward \n",
      "through our own operationsOur ambition\n",
      "\n",
      "Document 11: Document ID: 415 source: sparse\n",
      "Content:\n",
      "chemistry\n",
      " Governance and engagement - Risk management; Stakeholder engagement - Supplier \n",
      "engagement\n",
      "Engagement with external targets and initiatives related to sustainable \n",
      "supply chains  Wor king together - Our approach - Supporting partners - Cloud customers and  \n",
      "commercial partners\n",
      " Governance and engagement - PartnershipsC12. Engagement\n",
      "Goals and targets Supplier environmental assessment-related targets Introd uction - Targets and progress summary\n",
      " Oper ating sustainably - Circular economy - Our approach - Working with suppliers\n",
      "Performance indicators New suppliers that were screened using environmental criteria  Governance and engagement - Risk management C12. Engagement\n",
      "Supplier renewable energy Opera ting sustainably - Net-zero carbon - Our approach - Advancing carbon-free energy - \n",
      "CFE inv estmentsC2. Risks and opportunities\n",
      "Negative environmental impacts in the supply chain and actions taken Oper ating sustainably - Circular economy - Supply chain\n",
      "\n",
      "Document 12: Document ID: 346 source: dense\n",
      "Content:\n",
      "World Business Council for Sustainable Development (WBCSD)Google has been a member of the WBCSD for several years and participates in a number of its initiatives. \n",
      "Were a\n",
      "ctively involved in initiatives related to improving well-being for people and the planet, including  \n",
      "shifting diets, consumer behavior changes, and regenerative agriculture. \n",
      "World Resources Institute (WRI)Google has a 13-year long relationship with WRI for impact-focused collaboration. Some key projects include developing a near-real-time land cover dataset ( Dynamic World ), deforestation monitoring and alerts ( Global \n",
      "Forest Watch ), ending commodity-driven deforestation and accelerating restoration ( Forest Data Partnership ), \n",
      "measuring and mitigating extreme heat ( supported by Google.org ), and educating stakeholders on 24/7 CFE.   84\n",
      "2023 Environmental Report  Awards and recognition\n",
      "2022 CDP Climate Change A List  \n",
      "Alphabet has been named to CDPs Climate Change A list,\n",
      "\n",
      "Document 13: Document ID: 139 source: sparse\n",
      "Content:\n",
      "development and deployment of these materials.\n",
      "In 2022, we filed a patent for using machine \n",
      "learning technology to improve our ability to prevent emissions from refrigerant leaks.\n",
      "Data centers\n",
      "Googles data centers are the engine of our company, powering products like Gmail, Google Cloud, Search, and YouTube for billions of people around the world. Weve worked to make Googles data centers some of the most efficient in the world, improving their environmental performance even as demand for our products has risen. Weve done this by designing, building, and operating each one to maximize efficient use of energy, water, \n",
      "and ma\n",
      "terials.\n",
      "Our long-standing data center efficiency  efforts are\n",
      "\n",
      "Document 14: Document ID: 67 source: dense\n",
      "Content:\n",
      "Our approach\n",
      "Supporting partners\n",
      "Investing in breakthrough \n",
      "innovation\n",
      "Creating ecosystems for \n",
      "collaboration\n",
      "The journey ahead\n",
      "   21\n",
      "2023 Environmental Report  Our ambition\n",
      "We believe that Google has a unique \n",
      "opportunity that extends beyond reducing \n",
      "the environmental impacts of our own \n",
      "operations and value chain. By organizing \n",
      "information about our planet and making \n",
      "it actionable through technology and \n",
      "platforms, we can help partners and \n",
      "customers create even more positive impact.\n",
      "Digital technologies  play a critical role in industry \n",
      "transitions, allowing us to measure and track sustainability \n",
      "progress, optimize the use of resources, reduce \n",
      "greenhouse gas emissions, and enable a more circular \n",
      "economy.50 Cloud computing and digital technologies \n",
      "underpin the transformation in many sectors, such as \n",
      "energy, transportation, and agriculture. Research  that \n",
      "we commissioned in 2022 found that 20%25% of whats \n",
      "required for the EUs 2050 net-zero goal requires some\n",
      "\n",
      "Document 15: Document ID: 432 source: sparse\n",
      "Content:\n",
      "2023 Environmental Report  market structures. If no such structure exists, then Google defines the grid \n",
      "region as the electricity-balancing authority where our data centers are \n",
      "located. Outside of the United States, the grid region most often refers to \n",
      "the geographic boundary of a country, because most grid system operators \n",
      "operate at the national level. Certain regions that span multiple countries \n",
      "are well interconnected and could be considered as one grid; however, \n",
      "our grid mix calculations already include import and export considerations \n",
      "and therefore take into account power flows from neighboring grids. In \n",
      "the future, we may update our definition as we work with grid operators to \n",
      "better understand how transmission constraints or congestion impact CFE \n",
      "measurement within and across grid regions.\n",
      "91 Contracted CFE is the hourly electricity production from clean energy \n",
      "projects whose electricity and associated environmental attributes are\n",
      "\n",
      "Document 16: Document ID: 66 source: dense\n",
      "Content:\n",
      "the United States for pre-owned products, such as used and refurbished products. The journey \n",
      "ahead\n",
      "While a single individuals actions may seem small, when \n",
      "billions of people have the tools to make more sustainable decisions, they add up to have a meaningful impact on their communities and the entire planet. \n",
      "Were excited by the opportunity to enable climate and \n",
      "environmental action far beyond Googles direct impact, through information and innovation.\n",
      "LEARN MORE\n",
      "  Empowering with technology\n",
      "  Google Maps eco-friendly routing\n",
      "  Searching for sustainability with Google\n",
      "  Supporting a clean energy future with Nest Renew\n",
      "  The search for sustainability   20\n",
      "2023 Environmental Report  Working \n",
      "together\n",
      "Were working together with our \n",
      "partners and customers to advance technology for sustainabilityOur ambition\n",
      "Our approach\n",
      "Supporting partners\n",
      "Investing in breakthrough \n",
      "innovation\n",
      "Creating ecosystems for \n",
      "collaboration\n",
      "The journey ahead\n",
      "   21\n",
      "2023 Environmental Report  Our ambition\n",
      "\n",
      "Document 17: Document ID: 91 source: sparse\n",
      "Content:\n",
      "EV Suitability Assessment helps organizations monitor their fleet of vehicles and make choices that minimize environmental impact.\n",
      "Data analytics tools from Google Cloud are also helping \n",
      "airlines. Lufthansa Group partnered with Google Cloud \n",
      "and Google Research to develop a platform that facilitates better planning and management of daily flight operations.\n",
      "Were helping organizations harness \n",
      "the power of data and AI to drive more intelligent supply chains.Renewable energy\n",
      "Wind farms are an important source of carbon-free electricity, but wind can fluctuate depending on the weather. Through Google Cloud, customers like Engie  (a global energy and renewables supplier) can optimize their wind portfolio in short-term power markets by predicting wind power output 36 hours ahead of actual generation  and making optimal hourly delivery \n",
      "commitments to the grid, a full day in advance.  \n",
      "Sustainability partner \n",
      "solutions\n",
      "Partner solutions are important to scale the impact for our\n",
      "\n",
      "Document 18: Document ID: 262 source: dense\n",
      "Content:\n",
      "135 \n",
      "Preserving nature is critical both to mitigating climate  \n",
      "change and adapting to it. We want nature and people to flourish together in the communities that Google calls  home, as well as the ecosystems where we source food  for the hundreds of cafes we operate. Our approach\n",
      "We strive to protect and enhance nature and biodiversity through our campuses and technology.\n",
      "Google has offices in nearly 60 countries around the world \n",
      "(as of year-end 2022). In these locations, we aim to protect and enhance nature and biodiversity through a four-pillar approach that starts with building biodiversity at our own office and campus developments, as well as protecting nature and making it more accessible in the surrounding communities where we operate (see Figure 24).\n",
      "Our approach further focuses on sourcing responsibly\n",
      "\n",
      "Document 19: Document ID: 22 source: sparse\n",
      "Content:\n",
      "cled/ Ongoing  36% 41% 2025our consumer hardware product portfolio by 2025 renewable material (see pg. 62 )\n",
      "% plastic-free Ongoing  Make product packaging 100% plastic-free by 2025 97% 96% 2025packaging (see pg. 63 )\n",
      "Significant  Achieve UL 2799 Zero Waste to Landfill certification at all final \n",
      "Supply chain % of sites certified 9% 90% 2022 progress  assembly consumer hardware manufacturing sites by 2022\n",
      "(see pg. 65 )   9\n",
      "2023 Environmental Report  \n",
      "Emerging opportunities\n",
      "As the world becomes increasingly aware of the need for sustainability, individuals, businesses, and communities are  \n",
      "looking for new ways to reduce their environmental impact. Artificial intelligence (AI) and the power of information to help individuals and organizations reduce emissions are two emerging opportunities that Google is focusing on to help build a more sustainable future.\n",
      "AI for sustainability\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = rag_chain_hybrid.invoke(user_query)\n",
    "retrieved_docs = result['context']\n",
    "\n",
    "print(f\"Original Question to Dense Search: {user_query}\\n\")\n",
    "print(f\"Relevance Score: {result['answer']['relevance_score']}\\n\")\n",
    "print(f\"Final Answer:\\n{result['answer']['final_answer']}\\n\\n\")\n",
    "print(\"Retrieved Documents:\")\n",
    "for i, doc in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"Document {i}: Document ID: {doc.metadata['id']} source: {doc.metadata['source']}\")\n",
    "    print(f\"Content:\\n{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "984d9cbf-996b-4f74-b7f2-2cf084813e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bda35e0-8eca-4caf-a320-91727cad07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content=chunk) for chunk in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b909f75-4a07-4bf6-af19-3a7dc1c53483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c33e4e9fdc84893ba81389a465513c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/906 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d859416047b94079bf20f9ab73ad0077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    test_size = 10,\n",
    "    distributions = {\n",
    "        simple: 0.5,\n",
    "        reasoning: 0.25,\n",
    "        multi_context: 0.25\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f213b7-52fc-4cd1-9d7d-d2b81c9f6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset DataFrame saved successfully in the local directory\n"
     ]
    }
   ],
   "source": [
    "testset_df = testset.to_pandas()\n",
    "testset_df.to_csv(os.path.join('testset_data.csv'), index=False)\n",
    "print(\"testset DataFrame saved successfully in the local directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "877510d7-fb87-4a03-bdbf-a418c5975ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset DataFrame loaded successfully from loacl directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the climate-conscious data center coo...</td>\n",
       "      <td>['In 2022, we described our climate-conscious ...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the significance of achieving certific...</td>\n",
       "      <td>['In 2022, we certified 90% of our established...</td>\n",
       "      <td>Achieving certification to the UL 2799 Zero Wa...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of the green badge in...</td>\n",
       "      <td>['When individuals search in Google Flights, t...</td>\n",
       "      <td>The green badge in Google Flights indicates fl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Google.org support nonprofit-led proje...</td>\n",
       "      <td>['Global Covenant of Mayors for Climate &amp; Ener...</td>\n",
       "      <td>Google.org provided a $10 million grant to ICL...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the title of Google's climate change p...</td>\n",
       "      <td>['Weve consistently supported strong climate ...</td>\n",
       "      <td>Realizing a carbon-free future: Googles Third...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does the climate-conscious data center coo...   \n",
       "1  What is the significance of achieving certific...   \n",
       "2  What is the significance of the green badge in...   \n",
       "3  How did Google.org support nonprofit-led proje...   \n",
       "4  What is the title of Google's climate change p...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['In 2022, we described our climate-conscious ...   \n",
       "1  ['In 2022, we certified 90% of our established...   \n",
       "2  ['When individuals search in Google Flights, t...   \n",
       "3  ['Global Covenant of Mayors for Climate & Ener...   \n",
       "4  ['Weve consistently supported strong climate ...   \n",
       "\n",
       "                                        ground_truth evolution_type metadata  \\\n",
       "0  The climate-conscious data center cooling stra...         simple     [{}]   \n",
       "1  Achieving certification to the UL 2799 Zero Wa...         simple     [{}]   \n",
       "2  The green badge in Google Flights indicates fl...         simple     [{}]   \n",
       "3  Google.org provided a $10 million grant to ICL...         simple     [{}]   \n",
       "4  Realizing a carbon-free future: Googles Third...         simple     [{}]   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_testset_df = pd.read_csv(os.path.join('testset_data.csv'))\n",
    "print(\"testset DataFrame loaded successfully from loacl directory\")\n",
    "saved_testset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a59118-0aca-4a74-8221-de4fd20c395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_testing_data = saved_testset_df.astype(str).to_dict(orient='list')\n",
    "saved_testing_dataset = Dataset.from_dict(saved_testing_data)\n",
    "\n",
    "saved_testing_dataset_sm = saved_testing_dataset.remove_columns([\"evolution_type\", \"episode_done\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d97ec9f1-3374-4320-ad5d-7f7b4521c51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'metadata'],\n",
       "    num_rows: 9\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_testing_dataset_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "590990f2-4b6a-4755-9256-9bb80d0cc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, ground_truth, rag_chain):\n",
    "    result = rag_chain.invoke(question)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": result['answer']['final_answer'],\n",
    "        \"contexts\": [doc.page_content for doc in result[\"context\"]],\n",
    "        \"ground_truth\": ground_truth\n",
    "    }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9132c1c3-ce40-4a64-bc26-ca3930f3d447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b2e4daf9e54f00b8bca7361b589e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_dataset_similarity = saved_testing_dataset_sm.map(lambda x: generate_answer(x[\"question\"], x[\"ground_truth\"], rag_chain_similarity), remove_columns=saved_testing_dataset_sm.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c5a15dd-09ca-4e1d-a89e-24f4e256886f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3977a1e486248149e44d2af996eb472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_dataset_hybrid = saved_testing_dataset_sm.map(lambda x: generate_answer(x['question'], x['ground_truth'], rag_chain_hybrid), remove_columns=saved_testing_dataset_sm.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dedc0bd1-9f78-4002-8704-34bb838d7b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4a98a1b6b4429eaa1377b499a0b45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the climate-conscious data center coo...</td>\n",
       "      <td>[85Were working to achieve 24/7 CFE through t...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.947529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704031</td>\n",
       "      <td>0.969970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the significance of achieving certific...</td>\n",
       "      <td>[In 2022, we certified 90% of our established ...</td>\n",
       "      <td>Achieving certification to the UL 2799 Zero Wa...</td>\n",
       "      <td>Achieving certification to the UL 2799 Zero Wa...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.989568</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687817</td>\n",
       "      <td>0.986564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of the green badge in...</td>\n",
       "      <td>[When individuals search in Google Flights, th...</td>\n",
       "      <td>The significance of the green badge in Google ...</td>\n",
       "      <td>The green badge in Google Flights indicates fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944709</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912444</td>\n",
       "      <td>0.983108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Google.org support nonprofit-led proje...</td>\n",
       "      <td>[In Europe, our CEO Sundar Pichai shared virtu...</td>\n",
       "      <td>Google.org supported nonprofit-led projects in...</td>\n",
       "      <td>Google.org provided a $10 million grant to ICL...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.908912</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506146</td>\n",
       "      <td>0.899584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the title of Google's climate change p...</td>\n",
       "      <td>[Weve consistently supported strong climate p...</td>\n",
       "      <td>The title of Google's climate change public po...</td>\n",
       "      <td>Realizing a carbon-free future: Googles Third...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986450</td>\n",
       "      <td>0.945798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does Google Flights use TIM for carbon emi...</td>\n",
       "      <td>[When individuals search in Google Flights, th...</td>\n",
       "      <td>Google Flights uses the Travel Impact Model (T...</td>\n",
       "      <td>Google Flights uses the Travel Impact Model (T...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894364</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599869</td>\n",
       "      <td>0.987709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does Google work with RSMetrics and Infosy...</td>\n",
       "      <td>[Many of our commercial customers are eager to...</td>\n",
       "      <td>Google works with RSMetrics and Infosys to hel...</td>\n",
       "      <td>Google partners with RSMetrics and Infosys to ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859395</td>\n",
       "      <td>0.966990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What environmental data does an auditor review...</td>\n",
       "      <td>[Assurance\\nWe obtain limited third-party assu...</td>\n",
       "      <td>An auditor reviews environmental data such as ...</td>\n",
       "      <td>An independent auditor reviews select environm...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932805</td>\n",
       "      <td>0.906041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631375</td>\n",
       "      <td>0.969973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Google aim to replenish more freshwat...</td>\n",
       "      <td>[In addition to focusing on responsible water ...</td>\n",
       "      <td>Google aims to replenish 20% more freshwater t...</td>\n",
       "      <td>Google aims to replenish 20% more freshwater t...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.924531</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648719</td>\n",
       "      <td>0.994876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does the climate-conscious data center coo...   \n",
       "1  What is the significance of achieving certific...   \n",
       "2  What is the significance of the green badge in...   \n",
       "3  How did Google.org support nonprofit-led proje...   \n",
       "4  What is the title of Google's climate change p...   \n",
       "5  How does Google Flights use TIM for carbon emi...   \n",
       "6  How does Google work with RSMetrics and Infosy...   \n",
       "7  What environmental data does an auditor review...   \n",
       "8  How does Google aim to replenish more freshwat...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [85Were working to achieve 24/7 CFE through t...   \n",
       "1  [In 2022, we certified 90% of our established ...   \n",
       "2  [When individuals search in Google Flights, th...   \n",
       "3  [In Europe, our CEO Sundar Pichai shared virtu...   \n",
       "4  [Weve consistently supported strong climate p...   \n",
       "5  [When individuals search in Google Flights, th...   \n",
       "6  [Many of our commercial customers are eager to...   \n",
       "7  [Assurance\\nWe obtain limited third-party assu...   \n",
       "8  [In addition to focusing on responsible water ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The climate-conscious data center cooling stra...   \n",
       "1  Achieving certification to the UL 2799 Zero Wa...   \n",
       "2  The significance of the green badge in Google ...   \n",
       "3  Google.org supported nonprofit-led projects in...   \n",
       "4  The title of Google's climate change public po...   \n",
       "5  Google Flights uses the Travel Impact Model (T...   \n",
       "6  Google works with RSMetrics and Infosys to hel...   \n",
       "7  An auditor reviews environmental data such as ...   \n",
       "8  Google aims to replenish 20% more freshwater t...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  The climate-conscious data center cooling stra...      0.666667   \n",
       "1  Achieving certification to the UL 2799 Zero Wa...      0.714286   \n",
       "2  The green badge in Google Flights indicates fl...      1.000000   \n",
       "3  Google.org provided a $10 million grant to ICL...      0.888889   \n",
       "4  Realizing a carbon-free future: Googles Third...      1.000000   \n",
       "5  Google Flights uses the Travel Impact Model (T...      1.000000   \n",
       "6  Google partners with RSMetrics and Infosys to ...      1.000000   \n",
       "7  An independent auditor reviews select environm...      1.000000   \n",
       "8  Google aims to replenish 20% more freshwater t...      0.714286   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  answer_correctness  \\\n",
       "0          0.947529           1.000000        1.000000            0.704031   \n",
       "1          0.989568           1.000000        0.666667            0.687817   \n",
       "2          0.944709           0.835000        1.000000            0.912444   \n",
       "3          0.908912           0.111111        1.000000            0.506146   \n",
       "4          1.000000           1.000000        1.000000            0.986450   \n",
       "5          0.894364           0.916667        1.000000            0.599869   \n",
       "6          0.912609           1.000000        1.000000            0.859395   \n",
       "7          0.932805           0.906041        1.000000            0.631375   \n",
       "8          0.924531           0.988889        1.000000            0.648719   \n",
       "\n",
       "   answer_similarity  \n",
       "0           0.969970  \n",
       "1           0.986564  \n",
       "2           0.983108  \n",
       "3           0.899584  \n",
       "4           0.945798  \n",
       "5           0.987709  \n",
       "6           0.966990  \n",
       "7           0.969973  \n",
       "8           0.994876  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_similarity = evaluate(\n",
    "    testing_dataset_similarity,\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        answer_correctness,\n",
    "        answer_similarity]\n",
    ")\n",
    "similarity_df = score_similarity.to_pandas()\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33c73c60-b20a-4f6c-bfdf-6e7dc0d46513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b6ba8e294748428897b0d52b2283fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the climate-conscious data center coo...</td>\n",
       "      <td>[In 2022, we described our climate-conscious d...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>The climate-conscious data center cooling stra...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.972701</td>\n",
       "      <td>0.924442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.823432</td>\n",
       "      <td>0.986037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the significance of achieving certific...</td>\n",
       "      <td>[In 2022, we certified 90% of our established ...</td>\n",
       "      <td>Achieving certification to the UL 2799 Zero Wa...</td>\n",
       "      <td>Achieving certification to the UL 2799 Zero Wa...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.989568</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.746641</td>\n",
       "      <td>0.986564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of the green badge in...</td>\n",
       "      <td>[When individuals search in Google Flights, th...</td>\n",
       "      <td>The significance of the green badge in Google ...</td>\n",
       "      <td>The green badge in Google Flights indicates fl...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.979404</td>\n",
       "      <td>0.642674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713856</td>\n",
       "      <td>0.980423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Google.org support nonprofit-led proje...</td>\n",
       "      <td>[In Europe, our CEO Sundar Pichai shared virtu...</td>\n",
       "      <td>Google.org supported nonprofit-led projects in...</td>\n",
       "      <td>Google.org provided a $10 million grant to ICL...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957298</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.705492</td>\n",
       "      <td>0.946944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the title of Google's climate change p...</td>\n",
       "      <td>[Weve consistently supported strong climate p...</td>\n",
       "      <td>The title of Google's climate change public po...</td>\n",
       "      <td>Realizing a carbon-free future: Googles Third...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986450</td>\n",
       "      <td>0.945798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does Google Flights use TIM for carbon emi...</td>\n",
       "      <td>[When individuals search in Google Flights, th...</td>\n",
       "      <td>Google Flights uses the Travel Impact Model (T...</td>\n",
       "      <td>Google Flights uses the Travel Impact Model (T...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.902902</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782494</td>\n",
       "      <td>0.987119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does Google work with RSMetrics and Infosy...</td>\n",
       "      <td>[Many of our commercial customers are eager to...</td>\n",
       "      <td>Google works with RSMetrics and Infosys to hel...</td>\n",
       "      <td>Google partners with RSMetrics and Infosys to ...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.912609</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991933</td>\n",
       "      <td>0.967731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What environmental data does an auditor review...</td>\n",
       "      <td>[Assurance\\nWe obtain limited third-party assu...</td>\n",
       "      <td>An auditor reviews certain environmental data ...</td>\n",
       "      <td>An independent auditor reviews select environm...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934427</td>\n",
       "      <td>0.597092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897394</td>\n",
       "      <td>0.980879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Google aim to replenish more freshwat...</td>\n",
       "      <td>[In addition to focusing on responsible water ...</td>\n",
       "      <td>Google aims to replenish 20% more freshwater t...</td>\n",
       "      <td>Google aims to replenish 20% more freshwater t...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.924531</td>\n",
       "      <td>0.919151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.848721</td>\n",
       "      <td>0.994884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does the climate-conscious data center coo...   \n",
       "1  What is the significance of achieving certific...   \n",
       "2  What is the significance of the green badge in...   \n",
       "3  How did Google.org support nonprofit-led proje...   \n",
       "4  What is the title of Google's climate change p...   \n",
       "5  How does Google Flights use TIM for carbon emi...   \n",
       "6  How does Google work with RSMetrics and Infosy...   \n",
       "7  What environmental data does an auditor review...   \n",
       "8  How does Google aim to replenish more freshwat...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [In 2022, we described our climate-conscious d...   \n",
       "1  [In 2022, we certified 90% of our established ...   \n",
       "2  [When individuals search in Google Flights, th...   \n",
       "3  [In Europe, our CEO Sundar Pichai shared virtu...   \n",
       "4  [Weve consistently supported strong climate p...   \n",
       "5  [When individuals search in Google Flights, th...   \n",
       "6  [Many of our commercial customers are eager to...   \n",
       "7  [Assurance\\nWe obtain limited third-party assu...   \n",
       "8  [In addition to focusing on responsible water ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The climate-conscious data center cooling stra...   \n",
       "1  Achieving certification to the UL 2799 Zero Wa...   \n",
       "2  The significance of the green badge in Google ...   \n",
       "3  Google.org supported nonprofit-led projects in...   \n",
       "4  The title of Google's climate change public po...   \n",
       "5  Google Flights uses the Travel Impact Model (T...   \n",
       "6  Google works with RSMetrics and Infosys to hel...   \n",
       "7  An auditor reviews certain environmental data ...   \n",
       "8  Google aims to replenish 20% more freshwater t...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  The climate-conscious data center cooling stra...      0.400000   \n",
       "1  Achieving certification to the UL 2799 Zero Wa...      0.714286   \n",
       "2  The green badge in Google Flights indicates fl...      0.875000   \n",
       "3  Google.org provided a $10 million grant to ICL...      1.000000   \n",
       "4  Realizing a carbon-free future: Googles Third...      1.000000   \n",
       "5  Google Flights uses the Travel Impact Model (T...      0.500000   \n",
       "6  Google partners with RSMetrics and Infosys to ...      0.875000   \n",
       "7  An independent auditor reviews select environm...      1.000000   \n",
       "8  Google aims to replenish 20% more freshwater t...      0.777778   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  answer_correctness  \\\n",
       "0          0.972701           0.924442             1.0            0.823432   \n",
       "1          0.989568           0.990909             1.0            0.746641   \n",
       "2          0.979404           0.642674             1.0            0.713856   \n",
       "3          0.957298           0.444444             1.0            0.705492   \n",
       "4          1.000000           1.000000             1.0            0.986450   \n",
       "5          0.902902           0.840909             1.0            0.782494   \n",
       "6          0.912609           0.809524             1.0            0.991933   \n",
       "7          0.934427           0.597092             1.0            0.897394   \n",
       "8          0.924531           0.919151             1.0            0.848721   \n",
       "\n",
       "   answer_similarity  \n",
       "0           0.986037  \n",
       "1           0.986564  \n",
       "2           0.980423  \n",
       "3           0.946944  \n",
       "4           0.945798  \n",
       "5           0.987119  \n",
       "6           0.967731  \n",
       "7           0.980879  \n",
       "8           0.994884  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_hybrid = evaluate(\n",
    "    testing_dataset_hybrid,\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ]\n",
    ")\n",
    "hybrid_df = score_hybrid.to_pandas()\n",
    "hybrid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fc30f96-a6f5-4f77-a726-e9130552360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes saved successfully in the local directory.\n"
     ]
    }
   ],
   "source": [
    "key_columns = [\n",
    "    'faithfulness',\n",
    "    'answer_relevancy',\n",
    "    'context_precision',\n",
    "    'context_recall',\n",
    "    'answer_correctness',\n",
    "    'answer_similarity'\n",
    "]\n",
    "similarity_means = similarity_df[key_columns].mean()\n",
    "hybrid_means = hybrid_df[key_columns].mean()\n",
    "comparison_df = pd.DataFrame({'Similarity Run': similarity_means, 'Hybrid Run': hybrid_means})\n",
    "comparison_df['Difference'] = comparison_df['Similarity Run'] - comparison_df['Hybrid Run']\n",
    "\n",
    "similarity_df.to_csv(os.path.join('similarity_run_data.csv'), index=False)\n",
    "hybrid_df.to_csv(os.path.join('hybrid_run_data.csv'), index=False)\n",
    "comparison_df.to_csv(os.path.join('comparison_data.csv'), index=True)\n",
    "\n",
    "print(\"Dataframes saved successfully in the local directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4afd2168-2165-4032-9975-cf9d5ad415c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes loaded successfully from the local directory\n",
      "Performance Comparison\n",
      "\n",
      "**Retrieval**:\n",
      "                   Similarity Run  Hybrid Run  Difference\n",
      "context_precision        0.861967    0.796572    0.065396\n",
      "context_recall           0.962963    1.000000   -0.037037\n",
      "\n",
      "**Generation**:\n",
      "                  Similarity Run  Hybrid Run  Difference\n",
      "faithfulness            0.887125    0.793563    0.093563\n",
      "answer_relevancy        0.939447    0.952604   -0.013157\n",
      "\n",
      "**End to end evaluation**:\n",
      "                    Similarity Run  Hybrid Run  Difference\n",
      "answer_correctness        0.726249    0.832935   -0.106685\n",
      "answer_similarity         0.967175    0.975153   -0.007979\n"
     ]
    }
   ],
   "source": [
    "sem_df = pd.read_csv(os.path.join('similarity_run_data.csv'))\n",
    "rec_df = pd.read_csv(os.path.join('hybrid_run_data.csv'))\n",
    "comparison_df = pd.read_csv(os.path.join('comparison_data.csv'), index_col=0)\n",
    "print(\"Dataframes loaded successfully from the local directory\")\n",
    "print(\"Performance Comparison\")\n",
    "print(\"\\n**Retrieval**:\")\n",
    "print(comparison_df.loc[['context_precision', 'context_recall']])\n",
    "print(\"\\n**Generation**:\")\n",
    "print(comparison_df.loc[['faithfulness', 'answer_relevancy']])\n",
    "print(\"\\n**End to end evaluation**:\")\n",
    "print(comparison_df.loc[['answer_correctness', 'answer_similarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "725d0645-16ee-4da5-890a-f3f71b8dd343",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (4123410182.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    similarity_bars = ax.bar(x, comparison_df.loc[metric_list, 'Similarity Run'], width=bar_width, label='Similarity Run', color='#D51900', hatch'///')\u001b[0m\n\u001b[0m                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize(12, 18), sharex=False)\n",
    "bar_width = 0.35\n",
    "categories = ['Retrieval', 'Generation', 'End to end evaluation']\n",
    "metrics = [\n",
    "    ['context_precision', 'context_recall'],\n",
    "    ['faithfulness', 'answer_relevancy'],\n",
    "    ['answer_correctness', 'answer_similarity']]\n",
    "\n",
    "for i, (category, metric_list) in enumerate(zip(categories, metrics)):\n",
    "    ax = axex[i]\n",
    "    x = range(len(metric_list))\n",
    "    similarity_bars = ax.bar(x, comparison_df.loc[metric_list, 'Similarity Run'], width=bar_width, label='Similarity Run', color='#D51900', hatch'///')\n",
    "    for bar in similarity_bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.1%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    hybrid_bars = ax.bar([i + bar_width for i in x], comparison_df.loc[metric_list, 'Hybrid Run'], width=bar_width, label='Hybrid Run', color='#992111', hatch='\\\\\\\\\\\\')\n",
    "\n",
    "    # add values to Hybrid Run bars\n",
    "    for bar in hybrid_bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.1%}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    ax.set_title(category, fontsize=14, pad=20)\n",
    "    ax.set_xticks([i + bar_width / 2 for i in x])\n",
    "    ax.set_xticklabels(metric_list, rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "    # move the legend to the bottom right corner\n",
    "    ax.legend(fontsize=12, loc='lower right', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Add overall labels and title\n",
    "fig.text(0.04, 0.5, 'Scores', va='center', rotation='vertical', fontsize=14)\n",
    "fig.suptitle('Performance Comparison', fontsize=16)\n",
    "\n",
    "# adjust the spacing between subplots and increase the top margin\n",
    "plt.tight_layout(rect=[0.05, 0.03, 1, 0.95])\n",
    "plt.subplots_adjust(hspace=0.6, top=0.92)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
